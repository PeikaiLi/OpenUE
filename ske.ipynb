{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\未备份\\\\CS_Tutorial\\\\NLP\\\\Bert_Use\\\\OpenUE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.realpath('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文三元组联合抽取\n",
    "\n",
    "## 介绍\n",
    "\n",
    "在这个notebook中我们将使用openue库代码来训练我们自己的三元组联合抽取，使用的基础模型是`bert-base-chinese`，训练分为两步，首先训练关系分类模型，其次训练实体抽取模型。之后联合验证。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "在这个数据集中，使用ske数据集，具体例子如下。我们使用代码来读取`train.json`来分析一下数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/ske/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-09250cc6f881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../dataset/ske/train.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/ske/train.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../dataset/ske/train.json\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        example = json.loads(line)\n",
    "        break\n",
    "for k, v in example.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "\n",
    "## `seq model`关系分类模型\n",
    "\n",
    "如我们的模型图所示，我们需要先训练一个关系分类模型，识别出句子中实体的属性。也就是模型图中下方位置的关系类型识别模块，用来识别出句子中存在的关系。\n",
    "\n",
    "我们训练和验证模型使用的都是同一份代码，区别仅为`config`的设置不同，config具体的文件目录在`./config`下。\n",
    "<div  align=\"center\">\n",
    "    <img src=\"./imgs/architecture.png\" width = \"600\" height = \"400\" alt=\"图片名称\" align=center />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytorch_lightning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4d48b68254c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpytorch_lightning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopenue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlit_models\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlit_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_lightning'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import openue.lit_models as lit_models\n",
    "import yaml\n",
    "import time\n",
    "from transformers import AutoConfig\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一些参数和动态调用包\n",
    "def _import_class(module_and_class_name: str) -> type:\n",
    "    module_name, class_name = module_and_class_name.rsplit(\".\", 1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    class_ = getattr(module, class_name)\n",
    "\t\n",
    "    return class_\n",
    "\n",
    "\n",
    "def _setup_parser():\n",
    "    \"\"\"Set up Python's ArgumentParser with data, model, trainer, and other arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "    # Add Trainer specific arguments, such as --max_epochs, --gpus, --precision\n",
    "    # trainer_parser = pl.Trainer.add_argparse_args(parser)\n",
    "    # trainer_parser._action_groups[1].title = \"Trainer Args\"  # pylint: disable=protected-access\n",
    "    # parser = argparse.ArgumentParser(add_help=False, parents=[trainer_parser])\n",
    "\n",
    "    # Basic arguments\n",
    "    parser.add_argument(\"--wandb\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--litmodel_class\", type=str, default=\"SEQLitModel\")\n",
    "    parser.add_argument(\"--data_class\", type=str, default=\"REDataset\")\n",
    "    parser.add_argument(\"--model_class\", type=str, default=\"BertForRelationClassification\")\n",
    "    parser.add_argument(\"--load_checkpoint\", type=str, default=None)\n",
    "\n",
    "    # Get the data and model classes, so that we can add their specific arguments\n",
    "    temp_args, _ = parser.parse_known_args()\n",
    "    data_class = _import_class(f\"openue.data.{temp_args.data_class}\")\n",
    "    model_class = _import_class(f\"openue.models.{temp_args.model_class}\")\n",
    "\n",
    "    # Get data, model, and LitModel specific arguments\n",
    "    data_group = parser.add_argument_group(\"Data Args\")\n",
    "    data_class.add_to_argparse(data_group)\n",
    "\n",
    "    model_group = parser.add_argument_group(\"Model Args\")\n",
    "    model_class.add_to_argparse(model_group)\n",
    "\n",
    "    lit_model_group = parser.add_argument_group(\"LitModel Args\")\n",
    "    lit_models.BaseLitModel.add_to_argparse(lit_model_group)\n",
    "\n",
    "    parser.add_argument(\"--help\", \"-h\", action=\"help\")\n",
    "    return parser\n",
    "\n",
    "def _save_model(litmodel, tokenizer, path):\n",
    "    os.system(f\"mkdir -p {path}\")\n",
    "    litmodel.model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39585/2019715888.py:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "11/20/2021 13:09:07 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForRelationClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForRelationClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForRelationClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForRelationClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['relation_classification.bias', 'relation_classification.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "11/20/2021 13:09:19 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_seq\n",
      "11/20/2021 13:09:30 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_dev_BertTokenizerFast_seq\n",
      "11/20/2021 13:09:31 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_test_BertTokenizerFast_seq\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name    | Type                          | Params\n",
      "----------------------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss             | 0     \n",
      "1 | model   | BertForRelationClassification | 102 M \n",
      "----------------------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.378   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "298630040f5f4eea9c87f8d48352f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e50d62d34e42e8a63365420fb59fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xx/miniconda3/envs/py38/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "11/20/2021 13:10:49 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_seq\n"
     ]
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_seq.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "# logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "# if args.wandb:\n",
    "#     logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "#     logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "\n",
    "\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"seq_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实体识别模块\n",
    "\n",
    "在训练过程中，我们利用golden标签进行实体识别，即假设已经获得句子中存在的关系，之后利用这些关系来进行实体识别。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-90a04b961563>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "10/09/2021 14:28:34 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForNER: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForNER from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNER from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForNER were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['token_classification.weight', 'token_classification.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "10/09/2021 14:28:48 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_ner\n",
      "10/09/2021 14:29:08 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_dev_BertTokenizerFast_ner\n",
      "10/09/2021 14:29:08 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_test_BertTokenizerFast_ner\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type              | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss | 0     \n",
      "1 | model   | BertForNER        | 102 M \n",
      "----------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.249   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d0d7adf28d4657bed2df5f45cafb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e748258f39b14f95bbe29405c8b84b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/09/2021 14:29:18 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_ner\n",
      "10/09/2021 14:29:34 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_dev_BertTokenizerFast_ner\n",
      "10/09/2021 14:29:35 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_test_BertTokenizerFast_ner\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219d671ab4054c40b4aa8830bf999751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test/f1': 0.7528725268526352}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_ner.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证\n",
    "\n",
    "由于我们使用pipeline模型，所以无法联合训练，需要分别训练后进行统一验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-3220da989028>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "10/09/2021 14:30:54 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "10/09/2021 14:31:06 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_interactive\n",
      "10/09/2021 14:31:19 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_dev_BertTokenizerFast_interactive\n",
      "10/09/2021 14:31:19 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_test_BertTokenizerFast_interactive\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5294cf02128480b90b22adc453da0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'Test/f1': 0.0}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Test/f1': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_infer.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "if \"infer\" not in path :trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ee29d4c65a463677a56f7e718e0fe6afedbb1a78c06a034d94d3fcc7a37838e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
